"""
Â©Copyright 2020 University of Florida Research Foundation, Inc. All rights reserved.
Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).
"""
import torch

import kernet.utils as utils


class Phi(torch.nn.Module):
    """
    Implements the kernel feature maps for the higher-level kernelized network layers. 

    Perform all sanity checks at this level.
    """

    def __init__(self, kernel='gaussian', in_features=None, evaluation='direct', sigma=1., *args, **kwargs):
        super(Phi, self).__init__(*args, **kwargs)
        # sanity check done at network level, now in ['direct', 'indirect']
        self.evaluation = evaluation
        k_name = kernel.lower()
        if k_name not in ['gaussian', 'nn_tanh', 'nn_sigmoid', 'nn_relu', 'nn_reapen']:
            raise ValueError('Invalid kernel function: {}'.format(kernel))

        # kernel params
        self.k_params = {
            'sigma': sigma,
        }

        if k_name == 'gaussian':
            self.k_min, self.k_max = 0., 1.
            if evaluation == 'indirect':
                self.phi_fn = utils.gaussian_phi_fn_indir
            else:
                raise NotImplementedError()
        elif k_name == 'nn_tanh':
            self.k_min, self.k_max = -1., 1.
            if evaluation == 'indirect':
                raise NotImplementedError()
            else:
                self.phi_fn = utils.nn_tanh_phi_fn_dir
                # in direct mode, out_features will be used by, say, kLinear to
                # determine the shape of the downstream linear layer
                self.out_features = in_features
        elif k_name == 'nn_sigmoid':
            self.k_min, self.k_max = 0., 1.
            if evaluation == 'indirect':
                raise NotImplementedError()
            else:
                self.phi_fn = utils.nn_sigmoid_phi_fn_dir
                self.out_features = in_features
        elif k_name == 'nn_relu':
            self.k_min, self.k_max = 0., 1.
            if evaluation == 'indirect':
                raise NotImplementedError()
            else:
                self.phi_fn = utils.nn_relu_phi_fn_dir
                self.out_features = in_features
        elif k_name == 'nn_reapen':
            self.k_min, self.k_max = 0., 1.
            if evaluation == 'indirect':
                raise NotImplementedError()
            else:
                self.phi_fn = utils.nn_reapen_phi_fn_dir
                self.out_features = in_features

    def forward(self, input, centers=None):
        """
        If evaluation is 'indirect':
          x -> (k(c_1, x), ..., k(c_m, x)), c_i \in centers, \forall i.

        If evaluation is 'indirect':
          x -> \phi(x).T, where \phi(x) is the feature map of the kernel.

        Shape:
          input: (N, d1, d2, ...)
          centers: (M, d1, d2, ...)
        """
        if self.evaluation == 'indirect':
            if centers.size()[1:] != input.size()[1:]:
                raise ValueError(
                    'For input and centers, all dimensions except maybe the first one must match.')

            return self.phi_fn(input, centers, **self.k_params)
        else:
            return self.phi_fn(input, **self.k_params)

    def get_k_mtrx(self, input1, input2):
        if self.evaluation == 'indirect':
            return self(input1, centers=input2)
        else:
            return self(input1).mm(self(input2).t())

    def get_ideal_k_mtrx(self, target1, target2, n_classes):
        """
        Returns the "ideal" kernel matrix G* defined as
          (G*)_{ij} = k_min if y_i == y_j;
          (G*)_{ij} = k_max if y_i != y_j.

        Args:
          target1 (tensor): Categorical labels with values in 
            {0, 1, ..., n_classes-1}.
          target2 (tensor): Categorical labels with values in 
            {0, 1, ..., n_classes-1}.
          n_classes (int)

        Shape:
          - Input:
            target1: (n_examples1, 1) or (1,) (singleton set)
            target2: (n_examples2, 1) or (1,) (singleton set)
          - Output: (n_examples1, n_examples2)
        """
        if n_classes < 2:
            raise ValueError('You need at least 2 classes')

        if len(target1.size()) == 1:
            target1.unsqueeze_(1)
        elif len(target1.size()) > 2:
            raise ValueError('target1 has too many dimensions')
        if len(target2.size()) == 1:
            target2.unsqueeze_(1)
        elif len(target2.size()) > 2:
            raise ValueError('target2 has too many dimensions')

        if torch.max(target1) + 1 > n_classes:
            raise ValueError('target1 has at least one invalid entry')
        if torch.max(target2) + 1 > n_classes:
            raise ValueError('target2 has at least one invalid entry')

        target1_onehot, target2_onehot = \
            utils.one_hot_encode(target1, n_classes).to(torch.float), \
            utils.one_hot_encode(target2, n_classes).to(torch.float)

        ideal = target1_onehot.mm(target2_onehot.t())

        if self.k_min != 0:
            min_mask = torch.full_like(ideal, self.k_min)
            ideal = torch.where(ideal == 0, min_mask, ideal)
        if self.k_max != 1:
            max_mask = torch.full_like(ideal, self.k_max)
            ideal = torch.where(ideal == 1, max_mask, ideal)

        return ideal
