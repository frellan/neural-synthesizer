"""
Â©Copyright 2020 University of Florida Research Foundation, Inc. All rights reserved.
Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).
"""
# import os
# import logging

# import torch
# from torch.optim.lr_scheduler import ReduceLROnPlateau


# logger = logging.getLogger()


# class BaseTrainer(torch.nn.Module):
#     def __init__(self, opt, model=None, set_eval=None, optimizer=None,
#                  val_metric_name='acc', val_metric_obj='max'):
#         """
#         Args:
#           set_eval: Part of the model to be set to eval during training
#           val_metric_name (str): The name of the validation metric. Just 
#             some helpful information to be logged. Can be any name. Default: 'acc'.
#           val_metric_obj (str): Whether to minimize or maximize the validation
#             metric. One of 'min' or 'max'. Default: 'max'.
#         """
#         super(BaseTrainer, self).__init__()
#         if val_metric_obj not in ['min', 'max']:
#             raise ValueError()
#         self.opt = opt
#         self.steps_taken = 0  # the total number of train steps taken
#         self.start_epoch = 0
#         self.val_metric_name = val_metric_name
#         self.val_metric_obj = val_metric_obj
#         self.best_val_metric = float(
#             'inf') if val_metric_obj == 'min' else -float('inf')
#         self.model = model
#         self.set_eval = set_eval

#         if opt.is_train:
#             self.optimizer = optimizer
#             if opt.schedule_lr:
#                 self.scheduler = ReduceLROnPlateau(self.optimizer, val_metric_obj,
#                                                    factor=opt.lr_schedule_factor,
#                                                    patience=opt.lr_schedule_patience, verbose=True)

    # def load(self, model_name='net.pth'):
    #     filename = os.path.join(self.opt.checkpoint_dir, model_name)
    #     if not os.path.isfile(filename):
    #         logger.warning('Did not load {} since {} does not exist.'.format(
    #             model_name, filename))
    #         return

    #     logger.info('Loading checkpoint from {}...'.format(filename))
    #     checkpoint = torch.load(filename)

    #     try:
    #         self.model.load_state_dict(checkpoint['state_dict'])
    #     except RuntimeError:
    #         own_keys = set(self.model.state_dict().keys())
    #         load_keys = set(checkpoint['state_dict'].keys())
    #         missing = own_keys - load_keys
    #         extra = load_keys - own_keys
    #         if missing:
    #             logger.warning(
    #                 'Missing keys from model checkpoint:\n' + ', '.join(sorted(missing)))
    #         if extra:
    #             logger.warning(
    #                 'Extra keys from model checkpoint:\n' + ', '.join(sorted(extra)))
    #         logger.warning(
    #             'Loading only the matched keys from model checkpoint...')
    #         self.model.load_state_dict(checkpoint['state_dict'], strict=False)

    #     if self.opt.is_train:
    #         if self.opt.schedule_lr:  # TODO potentially overrides new params
    #             try:
    #                 self.scheduler.load_state_dict(
    #                     checkpoint['scheduler_state_dict'])
    #             except KeyError:
    #                 # this is useful in cases where the saved model did not use lr scheduling but one
    #                 # wants to schedule lr for fine-tuning
    #                 logger.warning(
    #                     'Did not find scheduler state dict from checkpoint. Not loading it...')

    #         self.best_val_metric = checkpoint['best_val_metric']
    #         self.steps_taken = checkpoint['steps_taken']
    #         # start from the next epoch of the previously saved epoch as we only save
    #         # at the end of an epoch
    #         self.start_epoch = checkpoint['epoch'] + 1
    #         logger.debug('Current best val metric ({}): {:.3f}.'.format(
    #             self.val_metric_name, self.best_val_metric))
    #         # all epoch numbers are 0-indexed
    #         logger.debug('Now starting from epoch {}...'.format(
    #             self.start_epoch+1))
    #     logger.info('Checkpoint loaded!')

    # def step(self, input, target, criterion, minimize=True):
    #     """
    #     Sets model to train mode, then perform one training step.

    #     Returns:
    #       output: Model output (without backward graph).
    #       loss: Loss value (without backward graph).
    #       minimize (bool): Whether to minimize or maximize the criterion.
    #         Default: True.
    #     """
    #     raise NotImplementedError()

    # def get_eval_output(self, input):
    #     """
    #     Sets model to eval mode, then evaluates the output from input
    #     without tracking the backward graph.

    #     Returns:
    #       output: Model output (without backward graph).
    #     """
    #     raise NotImplementedError()

    # def scheduler_step(self, val_loss_value):
    #     self.scheduler.step(val_loss_value)

    # def log_loss_values(self, loss_dict):
    #     for k, v in loss_dict.items():
    #         logger.add_scalar(k, v, self.steps_taken)
